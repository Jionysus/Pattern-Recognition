{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "BQ8dHVXBOnvv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Handwritten Digit classification using PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "1yvJ2r8QIZtz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Install PyTorch\n",
        "\n",
        "By default, PyTorch is not installed in the environment. So, you have to install it every time. \n",
        "\n",
        "Run the cell below for installing PyTorch."
      ]
    },
    {
      "metadata": {
        "id": "VBYtajKgJAei",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "!pip3 install torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x636uzviJ9jZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import PyTorch library \n",
        "\n",
        "- Import PyTorch by using the **```import torch```** command.\n",
        "\n",
        "- You can check the version of PyTorch by using **```torch.__version__```** command.\n",
        "\n",
        "- Use **```torch.cuda.is_available()```** to determint if your environment support GPU, which should return **```True```**. \n",
        "\n",
        "- If **```torch.cuda.is_available()```** returns **```False```**, you should change the accelerator from **None** to **GPU** (Refer to lab sheet section 3.1.7). "
      ]
    },
    {
      "metadata": {
        "id": "bl1CL96QJ8QM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__) # Return 0.3.0.post4\n",
        "print(torch.cuda.is_available()) # Return True, if GPU is available"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7kSLv8ubR15d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import other necessary libraries"
      ]
    },
    {
      "metadata": {
        "id": "AVkR-UlkSgxQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_N0LONGPSvPH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define the hyperparameters of the neural network.\n",
        "\n",
        "**You will need to modify some of the training parameters for answering the questions.**"
      ]
    },
    {
      "metadata": {
        "id": "J25h4ZhrS6OY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 32\n",
        "learning_rate = 0.1\n",
        "num_epochs = 30\n",
        "weight_decay_coef = 0 # Modify this for Q.4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yFF4aJVYTnfX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MNIST handwrittern digit dataset\n",
        "\n",
        "Create the data loaders: one for **training** and one for **evaluation**."
      ]
    },
    {
      "metadata": {
        "id": "LWOkzMYWTmlC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=1, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=1, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MYwUt9bYUt23",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualizing the dataset"
      ]
    },
    {
      "metadata": {
        "id": "jrDs5UorUZTG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig=plt.figure()\n",
        "columns = 4\n",
        "rows = 5\n",
        "for i in range(1, columns*rows+1):\n",
        "    # Try to change: train_dataset -> test_dataset, and run it again\n",
        "    img = train_dataset.__getitem__(i-1)[0][0].numpy()\n",
        "    \n",
        "    h, w = img.shape\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DmcWO-EQXTIK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build a 3-layer Multi-Layer Perceptron (MLP)\n",
        "\n",
        "![MLP](https://www.pyimagesearch.com/wp-content/uploads/2016/08/simple_neural_network_header-768x377.jpg =x200)\n",
        "\n",
        "The reason for calling it as \"3-layer\" is that there are 3 sets of trainable parameters (i.e. 3 sets of weights and bias).\n"
      ]
    },
    {
      "metadata": {
        "id": "vGU7XqMFXUFu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    # Define the structure\n",
        "    def __init__(self, in_dim, h1_dim, h2_dim, out_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(in_dim, h1_dim, bias=True)\n",
        "        self.layer2 = nn.Linear(h1_dim, h2_dim, bias=True)\n",
        "        self.layer3 = nn.Linear(h2_dim, out_dim)\n",
        "\n",
        "    # Define the forward pass operations    \n",
        "    def forward(self, x):\n",
        "        # Reshape the img: batch_size*28*28 -> batch_size*784 \n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        #x = F.relu(x) # Uncommend it for adding ReLU activation. Modify it for Q.3\n",
        "        x = self.layer2(x)\n",
        "        #x = F.relu(x) # Uncommend it for adding ReLU activation. Modify it for Q.3\n",
        "        x = self.layer3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tRvs-BUOH0Fy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build a Convolutional Neural Network (CNN)\n",
        "\n",
        "![CNN](https://raw.github.com/floydhub/mnist/master/images/mnist_convet.png)"
      ]
    },
    {
      "metadata": {
        "id": "kJmuQCTkIU7e",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = x.view(-1, 320)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Eoo_n3KIWWP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create the models of the MLP and the CNN."
      ]
    },
    {
      "metadata": {
        "id": "nTzyfmkeixnF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create a model of the MLP\n",
        "# Define the hyperparameter as follows: \n",
        "# in_dim=28*28, h1_dim=128, h2_dim=128, out_dim=10\n",
        "model_mlp = MLP(in_dim=28*28, h1_dim=128, h2_dim=128, out_dim=10)\n",
        "\n",
        "# Convert all model's trainable parameters to CUDA Tensor\n",
        "# to train with GPU\n",
        "model_mlp = model_mlp.cuda()\n",
        "\n",
        "#-------------------------------------------------------\n",
        "# Create a model of the CNN\n",
        "model_cnn = CNN()\n",
        "model_cnn = model_cnn.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2sgaWFxGpFW1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can display the details of the model."
      ]
    },
    {
      "metadata": {
        "id": "mALXwJIbn5bE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(model_mlp)\n",
        "\n",
        "print(model_cnn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ys_W510XUSdT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Also, we can list the number of trainable parameters in each layer.\n",
        "\n",
        "**Show the number of trainable parameters in layer1 of the MLP and conv1 of the CNN**"
      ]
    },
    {
      "metadata": {
        "id": "dP3sJixUpqeV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for param in model_mlp.layer1.parameters(): # Modify it for Q.1\n",
        "    print('Shape of parameters: ', param.shape)\n",
        "    print('Number of parameters: ', param.numel())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ObjKNPY_Oc_o",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for param in model_cnn.conv1.parameters(): # Modify it for Q.1\n",
        "    print('Shape of parameters: ', param.shape)\n",
        "    print('number of parameters: ', param.numel())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aCDsiLx6D9b7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a loss function and an optimizer."
      ]
    },
    {
      "metadata": {
        "id": "ZMYW0Yqk0aGS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Softmax operation is included inside the nn.CrossEntropyLoss function\n",
        "# Refer to: http://pytorch.org/docs/master/nn.html#torch.nn.CrossEntropyLoss \n",
        "CELoss = nn.CrossEntropyLoss()\n",
        "\n",
        "# Stochastic gradient descent is used as the optimizer\n",
        "# One for the MLP, another one for the CNN\n",
        "SGD_mlp = optim.SGD(model_mlp.parameters(), lr=learning_rate, weight_decay=weight_decay_coef)\n",
        "SGD_cnn = optim.SGD(model_cnn.parameters(), lr=learning_rate, weight_decay=weight_decay_coef)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MspkBWQbrsut",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create the functions to train and evaluate the model\n",
        "\n",
        "In Python, **```def```** is used to define a function. We create **```train```** and **```test```** to train the model and evaluate the performance. "
      ]
    },
    {
      "metadata": {
        "id": "NgyHP5hCr653",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def train(loader, net, criterion, optimizer):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Make train model of the net is turned on\n",
        "    net.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_samples = 0.0\n",
        "    running_correct = 0.0\n",
        "\n",
        "    for data in loader:\n",
        "        img, label = data\n",
        "\n",
        "        running_samples += img.size(0)\n",
        "\n",
        "        # Convert to CUDA Tensor variable\n",
        "        # as we can only calculate the gradient of an variable\n",
        "        img = Variable(img).cuda()\n",
        "        label = Variable(label).cuda()\n",
        "\n",
        "        # Feed forward\n",
        "        output_score = net(img) # dim. of output_score: batch_size*10\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(output_score, label)\n",
        "\n",
        "        # Backpropagation (3 steps)\n",
        "        # 1. Clear the gradients (i.e. all become zero)\n",
        "        # 2. Calculate the derivative of the loss with respect to the variables(trainable parameters)\n",
        "        # 3. Update the parameters (i.e. model.parameters(), as defined above) by using the optimizer\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, pred = torch.max(output_score, 1)\n",
        "        num_correct = (pred == label).sum().data[0]\n",
        "\n",
        "        running_loss += loss.data[0]\n",
        "        running_correct += num_correct\n",
        "\n",
        "    # Calculate the average loss and top-1 accuracy for each epoch\n",
        "    average_loss = running_loss / running_samples\n",
        "    average_accuracy = running_correct / running_samples\n",
        "\n",
        "    print('Training loss: {:.4f}, Acc: {:.4f} in {:.4f}'.format(\n",
        "          average_loss, \n",
        "          average_accuracy,\n",
        "          time.time()-start_time))\n",
        " \n",
        "#---------------------------------------------------------------------------------\n",
        "\n",
        "def test(loader, net, criterion):\n",
        "    #In testing phase, no need to update the network.\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Make eval model of the net is turned on\n",
        "    net.eval()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_samples = 0.0\n",
        "    running_correct = 0.0\n",
        "\n",
        "    for data in loader:\n",
        "        img, label = data\n",
        "\n",
        "        running_samples += img.size(0)\n",
        "\n",
        "        # Convert to CUDA Tensor variable\n",
        "        # as we can only calculate the gradient of an variable\n",
        "        img = Variable(img).cuda()\n",
        "        label = Variable(label).cuda()\n",
        "\n",
        "        # Feed forward\n",
        "        output_score = net(img) # dim. of output_score: batch_size*10\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(output_score, label)\n",
        "\n",
        "        _, pred = torch.max(output_score, 1)\n",
        "        num_correct = (pred == label).sum().data[0]\n",
        "\n",
        "        running_loss += loss.data[0]\n",
        "        running_correct += num_correct\n",
        "\n",
        "    # Calculate the average loss and top-1 accuracy for each epoch\n",
        "    average_loss = running_loss / running_samples\n",
        "    average_accuracy = running_correct / running_samples\n",
        "\n",
        "    print('Test loss: {:.4f}, Acc: {:.4f} in {:.4f}'.format(\n",
        "          average_loss, \n",
        "          average_accuracy,\n",
        "          time.time()-start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VZYUGXxovr4L",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# For training and test the MLP/CNN,\n",
        "# To train and test with CNN, change model_mlp->model_cnn and change SGD_mlp->SGD_cnn\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    print('Epoch: ', epoch)\n",
        "    train(train_loader, model_mlp, criterion=CELoss, optimizer=SGD_mlp) # Modify model_mlp, SGD_mlp for Q.2 and Q.4\n",
        "    test(test_loader, model_mlp, criterion=CELoss) # Modify model_mlp for Q.2 and Q.4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U6BCoIDR6ptL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print('Display the value of the trainable parameters in each layer:')\n",
        "for param in model_mlp.parameters(): # Modify for Q.4 (For CNN, change model_mlp->model_cnn)\n",
        "  print('Mean: {:.4f} Min.: {:.4f} Max.:{:.4f}'.format(\n",
        "      param.data.mean(), param.data.min(), param.data.max()))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}